{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import dotenv\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: AzureChatOpenAI = None\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Look at the image below and use it as input. Generate a response based on the image.\n",
    "You are an expert in ontology engineering. Generate an OWL ontology based on the following domain description:\n",
    "Define classes, data properties, and object properties with their designation, the norm name, a yes/no if the standard has been withdrawn and the respective name of the ISO/DIN norm.\n",
    "Include domain and range for each property.\n",
    "Provide the output in OWL (XML) format and only output the ontology and nothing else\"\"\"\n",
    "\n",
    "task_prompt = \"\"\"Generate an ontology based on the following domain description of screw specification in ISO and DIN norm. This is the existing ontology that you need to extend if necessary:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "        temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Convert PIL images to Base64 encoded strings\n",
    "\n",
    "    :param pil_image: PIL image\n",
    "    :return: Base64 string\n",
    "    \"\"\"\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")  # You can change the format if needed\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "def load_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image from a file path\n",
    "\n",
    "    :param image_path: Path to the image\n",
    "    :return: PIL image\n",
    "    \"\"\"\n",
    "    return Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../../data/Broschuere_DIN-EN-ISO_Normung_DE\"\n",
    "\n",
    "onthology_file_path=\"onthology_bolts.xml\"\n",
    "\n",
    "def process_file(image_file_path, onthology_file_path):\n",
    "    image_data = convert_to_base64(load_image(image_file_path))\n",
    "    with open(onthology_file_path, \"r\") as file:\n",
    "        ontology_content = file.read()\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\"type\": \"text\", \"text\": system_prompt + task_prompt + ontology_content},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/png;base64,{image_data}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    response = model.invoke([message])\n",
    "    print(response.content)\n",
    "\n",
    "    with open(onthology_file_path, \"w\") as file:\n",
    "        new_ontology = response.content.replace(\"```xml\", \"\").replace(\"```\", \"\")\n",
    "        file.write(new_ontology)\n",
    "\n",
    "folder = Path(image_path)\n",
    "\n",
    "files = [f for f in os.listdir(image_path) if os.path.isfile(os.path.join(image_path, f))]\n",
    "files.sort()\n",
    "for file in files:\n",
    "    file_path = Path(folder, file)\n",
    "    print(file_path)\n",
    "    process_file(file_path, onthology_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onthology-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
